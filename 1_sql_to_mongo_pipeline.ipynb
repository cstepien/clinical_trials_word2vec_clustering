{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL to MongoDB ETL pipeline: Extract, Transform, Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import pandas.io.sql as pd_sql\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a login parameter file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create an account on [AACT](https://aact.ctti-clinicaltrials.org/users/sign_up) to get access to the clinical trials database\n",
    "* Create a login.txt file with the database and login credentials formatted as below, adding in your specific username and password:\n",
    "\n",
    "`\n",
    "{\"host\": \"aact-db.ctti-clinicaltrials.org\", \"user\": \"username\", \"password\": \"password\", \"dbname\": \"aact\", \"port\": 5432}`\n",
    "\n",
    "* Save the login.txt file in the same directory as the python scripts/notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions for the SQL to MongoDB ETL pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning functions: creating a dictionary (document) from a SQL record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The SQL cursor will return an unlabeled tuple, instead of a dataframe with labeled columns like a standard query would return. So I need to index the tuple based on where the information I want is using the [AACT database schema](https://aact.ctti-clinicaltrials.org/static/documentation/aact_schema.png) \n",
    "* A different cleaning function will be specified for each SQL table queried from AACT\n",
    "* Cleaning functions will be referenced later in the pipeline function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eligibilities table cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_eligibility_record(record):\n",
    "    \n",
    "    \"\"\"Takes an AACT database read from an SQL cursor and produces a dictionary. \n",
    "    Removes new lines and extra spaces from eligibility criteria. \n",
    "    Returns a dictionary in document form to be sent to mongodb.\"\"\"\n",
    "    \n",
    "    document = {}\n",
    "    document['study_id'] = record[1]\n",
    "    document['minimum_age'] = record[4]\n",
    "    document['maximum_age'] = record[5]\n",
    "    document['gender'] = record[3]\n",
    "    document['keyword'] = record[-1]\n",
    "    \n",
    "    eligibility = record[8]\n",
    "    eligibility = eligibility.replace('\\n             ', ' ')  \n",
    "    \n",
    "    # Focus on records with 1 set of inclusion criteria and 1 set of exclusion criteria\n",
    "    regex = '-\\s\\s(.+)\\n\\n'\n",
    "    if eligibility.count('Inclusion') == 1 and eligibility.count('Exclusion') == 1:\n",
    "        inclusion, exclusion = eligibility.split('Exclusion')\n",
    "        clean_inclusion = re.findall(regex, inclusion)\n",
    "        clean_exclusion = re.findall(regex, exclusion)\n",
    "        # Currently allows empty list values to be passed to dictionary\n",
    "        # Many records have numbered lists of criteria, so regex fails\n",
    "        # These empty values are caught in the sql_to_mongo pipeline\n",
    "        document['inclusion_criteria'] = clean_inclusion\n",
    "        document['exclusion_criteria'] = clean_exclusion\n",
    "    else:\n",
    "        document['inclusion_criteria'] = None\n",
    "        document['exclusion_criteria'] = None\n",
    "        print(f\"Skipped study {document['study_id']}: Inclusion/Exclusion set != 1\\n\")\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Add document to MongoDB function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_mongodb(document, client_connection):\n",
    "    \n",
    "    \"\"\"Takes a dictionary in document form and sends it to a pre-specified database\n",
    "    and collection in mongodb. document is the document to enter into the database. \n",
    "    client_connection is an already opened connection with a MongoDB client pointing\n",
    "    to a specified location.\"\"\"\n",
    "    \n",
    "    mongo_result = client_connection.insert_one(document)\n",
    "    \n",
    "    if not mongo_result.acknowledged: \n",
    "        raise ValueError(\"Failed to add document to MongoDB. Check connection and document.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SQL query to MongoDB pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_to_mongo(query, cleaning_func, login, database, collection, check_size=None):\n",
    "    \n",
    "    \"\"\"SQL to MongoDB pipeline. Retrieves single SQL record from a cursor, \n",
    "    converts it into a dictionary, and inputs that to MongoDB.\n",
    "    query is a SQL query. cleaning_func is the cleaning function to use, depends on \n",
    "    the SQL table being queried.\n",
    "    login is a text file with the login parameters for the SQL database. \n",
    "    database and collections are strings of MongoDB locations.\n",
    "    check_size can be True or False.\"\"\"\n",
    "    \n",
    "    print(\"Connecting to SQL database...\\n\")\n",
    "    connection_args = json.load(open(login))\n",
    "    connection = pg.connect(**connection_args)\n",
    "    cursor = connection.cursor()\n",
    "    print(\"Executing query...\\n\")\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    print(\"Connecting to Mongo database...\\n\")\n",
    "    client = MongoClient()\n",
    "    db = client[database]\n",
    "    mongo_loc = db[collection]\n",
    "    \n",
    "    print(\"Cleaning data and sending to Mongo...\\n\")\n",
    "    for result in cursor:\n",
    "        document = cleaning_func(result)\n",
    "        # add extra line to check which cleaning function - do different data check depending on that\n",
    "        if document['inclusion_criteria']:\n",
    "            send_to_mongodb(document, mongo_loc)\n",
    "        else:\n",
    "            print(f\"Skipped study {document['study_id']}: formatted differently\\n\")\n",
    "    \n",
    "    if check_size:\n",
    "        size_data = db.command(\"dbstats\")\n",
    "        print(\"------ Database Stats ------\\n\", \n",
    "              \"\\nNumber of collections:\", size_data['collections'], \n",
    "              \"\\nNumber of objects:\", size_data['objects'],\n",
    "             \"\\nAverage object size:\", size_data['avgObjSize'], 'bytes', \n",
    "             \"\\nData Size:\", size_data['dataSize'], 'bytes', \n",
    "              \"\\nStorage Size:\", size_data['storageSize'], 'bytes\\n')\n",
    "    print(\"Done.\")\n",
    "    connection.close()\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query test for keywords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x10dfe3188>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client = MongoClient()\n",
    "# db = client['clinical_trials']\n",
    "# mongo_loc = db['eligibilities']\n",
    "\n",
    "# mongo_loc.update_many({}, {\"$set\" : {\"keyword\":null}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "pymongo.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT nct_id, downcase_name FROM keywords;\"\n",
    "\n",
    "# query = \"SELECT * FROM keywords LIMIT 10\"\n",
    "\n",
    "connection_args = json.load(open('login.txt'))\n",
    "connection = pg.connect(**connection_args)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query)\n",
    "\n",
    "client = MongoClient()\n",
    "db = client['clinical_trials']\n",
    "mongo_loc = db['eligibilities']\n",
    "i = 0\n",
    "\n",
    "for result in cursor:\n",
    "    i += 1\n",
    "    if i % 5000 == 0:\n",
    "        print('On study', i)\n",
    "    nct_id = result[0]\n",
    "    keyword = result[1]\n",
    "    mongo_loc.update_one({\"study_id\": nct_id}, {\"$set\": {\"keyword\": keyword}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NCT02553811', 'diagnosis')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query test for recruitment status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x10d012308>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "db = client['clinical_trials']\n",
    "mongo_loc = db['eligibilities']\n",
    "\n",
    "mongo_loc.update_many({}, {\"$set\" : {\"status\": 'none'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On study 5000\n",
      "On study 10000\n",
      "On study 15000\n",
      "On study 20000\n",
      "On study 25000\n",
      "On study 30000\n",
      "On study 35000\n",
      "On study 40000\n",
      "On study 45000\n",
      "On study 50000\n",
      "On study 55000\n",
      "On study 60000\n",
      "On study 65000\n",
      "On study 70000\n",
      "On study 75000\n",
      "On study 80000\n",
      "On study 85000\n",
      "On study 90000\n",
      "On study 95000\n",
      "On study 100000\n",
      "On study 105000\n",
      "On study 110000\n",
      "On study 115000\n",
      "On study 120000\n",
      "On study 125000\n",
      "On study 130000\n",
      "On study 135000\n",
      "On study 140000\n",
      "On study 145000\n",
      "On study 150000\n",
      "On study 155000\n",
      "On study 160000\n",
      "On study 165000\n",
      "On study 170000\n",
      "On study 175000\n",
      "On study 180000\n",
      "On study 185000\n",
      "On study 190000\n",
      "On study 195000\n",
      "On study 200000\n",
      "On study 205000\n",
      "On study 210000\n",
      "On study 215000\n",
      "On study 220000\n",
      "On study 225000\n",
      "On study 230000\n",
      "On study 235000\n",
      "On study 240000\n",
      "On study 245000\n",
      "On study 250000\n",
      "On study 255000\n",
      "On study 260000\n",
      "On study 265000\n",
      "On study 270000\n",
      "On study 275000\n",
      "On study 280000\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT nct_id, overall_status FROM studies;\"\n",
    "\n",
    "# query = \"SELECT * FROM keywords LIMIT 10\"\n",
    "\n",
    "connection_args = json.load(open('login.txt'))\n",
    "connection = pg.connect(**connection_args)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query)\n",
    "i = 0\n",
    "\n",
    "for status in cursor:\n",
    "    i += 1\n",
    "    if i % 5000 == 0:\n",
    "        print('On study', i)\n",
    "    nct_id = status[0]\n",
    "    study_status = status[1]\n",
    "    mongo_loc.update_one({\"study_id\": nct_id}, {\"$set\": {\"status\": study_status}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "social anxiety disorder\n",
      "quetiapine xr\n",
      "prevention\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM eligibilities JOIN keywords ON eligibilities.nct_id = keywords.nct_id LIMIT 3;\"\n",
    "\n",
    "# query = \"SELECT * FROM keywords LIMIT 10\"\n",
    "\n",
    "connection_args = json.load(open('login.txt'))\n",
    "connection = pg.connect(**connection_args)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query)\n",
    "\n",
    "for result in cursor:\n",
    "    print(result[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to SQL database...\n",
      "\n",
      "Executing query...\n",
      "\n",
      "Connecting to Mongo database...\n",
      "\n",
      "Cleaning data and sending to Mongo...\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2ebedfb29d71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SELECT * FROM keywords LIMIT 3;\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msql_to_mongo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_eligibility_record\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'login.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'testdb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'keywords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-5c50a64ef4e5>\u001b[0m in \u001b[0;36msql_to_mongo\u001b[0;34m(query, cleaning_func, login, database, collection, check_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cleaning data and sending to Mongo...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaning_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m# add extra line to check which cleaning function - do different data check depending on that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inclusion_criteria'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-f542fb5c6f57>\u001b[0m in \u001b[0;36mclean_eligibility_record\u001b[0;34m(record)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'study_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'minimum_age'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximum_age'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM keywords LIMIT 3;\"\n",
    "sql_to_mongo(query, clean_eligibility_record, 'login.txt', 'testdb', 'keywords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate average size of one document to determine whether to store the full set of 280k trials on local machine or AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to SQL database...\n",
      "\n",
      "Executing query...\n",
      "\n",
      "Connecting to Mongo database...\n",
      "\n",
      "Cleaning data and sending to Mongo...\n",
      "\n",
      "Skipped study NCT00864357: formatted differently\n",
      "\n",
      "Skipped study NCT00864890: formatted differently\n",
      "\n",
      "Skipped study NCT00864877: formatted differently\n",
      "\n",
      "Skipped study NCT00864825: formatted differently\n",
      "\n",
      "Skipped study NCT00864747: formatted differently\n",
      "\n",
      "Skipped study NCT00864604: formatted differently\n",
      "\n",
      "Skipped study NCT00864552: Inclusion/Exclusion set != 1\n",
      "\n",
      "Skipped study NCT00864552: formatted differently\n",
      "\n",
      "Skipped study NCT00864526: formatted differently\n",
      "\n",
      "Skipped study NCT00864487: Inclusion/Exclusion set != 1\n",
      "\n",
      "Skipped study NCT00864487: formatted differently\n",
      "\n",
      "Skipped study NCT00864435: formatted differently\n",
      "\n",
      "Skipped study NCT00858208: formatted differently\n",
      "\n",
      "Skipped study NCT00864331: Inclusion/Exclusion set != 1\n",
      "\n",
      "Skipped study NCT00864331: formatted differently\n",
      "\n",
      "Skipped study NCT00864318: formatted differently\n",
      "\n",
      "Skipped study NCT00864279: formatted differently\n",
      "\n",
      "Skipped study NCT00864214: formatted differently\n",
      "\n",
      "Skipped study NCT00864149: formatted differently\n",
      "\n",
      "Skipped study NCT00864071: formatted differently\n",
      "\n",
      "Skipped study NCT00863928: Inclusion/Exclusion set != 1\n",
      "\n",
      "Skipped study NCT00863928: formatted differently\n",
      "\n",
      "Skipped study NCT00863902: formatted differently\n",
      "\n",
      "Skipped study NCT00863863: formatted differently\n",
      "\n",
      "Skipped study NCT00863733: formatted differently\n",
      "\n",
      "------ Database Stats ------\n",
      " \n",
      "Number of collections: 1 \n",
      "Number of objects: 79 \n",
      "Average object size: 1417.7215189873418 bytes \n",
      "Data Size: 112000.0 bytes \n",
      "Storage Size: 4096.0 bytes\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM eligibilities LIMIT 100;\"\n",
    "sql_to_mongo(query, clean_eligibility_record, 'login.txt', 'file_size', 'trials', check_size=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get all eligibility data from the AACT clinical trials database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM eligibilities;\"\n",
    "sql_to_mongo(query, clean_eligibility_record, 'login.txt', 'clinical_trials', 'eligibilities', check_size=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Open a branch to work on including studies currently skipped due to eligibility formatting.\n",
    "   Around ~30% of studies are currently excluded: \n",
    "> * some have numbered lists of criteria instead of bulleted lists and are not matched to the current regex for dashed bullets. Therefore sometimes document\\['inclusion criteria'\\] values are turning up False/empty and not sent to MongoDB\n",
    "> * some have multiple sets of inclusion and exclusion criteria for different cohorts, treatments, control vs. treatment, etc.\n",
    "> * some have the word 'inclusion' or 'exclusion' used more than once within a single set of critera\n",
    "> * a small percent (<0.05%) have INCLUSION or EXCLUSION listed in caps instead of lower case (use a regex and then only split on the first instance of 'exclusion')\n",
    "> * Some studies have exclusion criteria before inclusion criteria, so splitting on exclusion leads to no inclusion criteria  \n",
    "* The below searches for case-insensitive values, but does worse overall because it excludes records that have a capital 'Inclusion' that denotes the inclusion criteria but a lower-case inclusion clarifying data - as well as the above issues\n",
    "\n",
    "```python   \n",
    "    regex_crit = '-\\s\\s(.+)\\n\\n'\n",
    "    regex_inc = 'inclusion'\n",
    "    regex_exc = 'exclusion'\n",
    "    \n",
    "    num_inc_matches = len(re.findall(regex_inc, eligibility, re.IGNORECASE))\n",
    "    num_exc_matches = len(re.findall(regex_exc, eligibility, re.IGNORECASE))\n",
    "\n",
    "    # if case-sensitive 'inclusion' appears more than once, it gets dropped\n",
    "    if num_inc_matches == 1 and num_exc_matches == 1:\n",
    "        inclusion, exclusion = re.split('Exclusion', eligibility, flags=re.IGNORECASE)\n",
    "        clean_inclusion = re.findall(regex_crit, inclusion)\n",
    "        clean_exclusion = re.findall(regex_crit, exclusion)\n",
    "        document['inclusion_criteria'] = clean_inclusion\n",
    "        document['exclusion_criteria'] = clean_exclusion\n",
    "    # looking at studies even if they don't have exclusion criteria\n",
    "    elif num_inc_matches == 1 and num_exc_matches == 0:\n",
    "        clean_inclusion = re.findall(regex_crit, eligibility)\n",
    "        document['inclusion_criteria'] = clean_inclusion\n",
    "        document['exclusion_criteria'] = None\n",
    "    else:\n",
    "        document['inclusion_criteria'] = None\n",
    "        document['exclusion_criteria'] = None\n",
    "        print(f\"Skipped study {document['study_id']}\\n\")\n",
    "    return document\n",
    "```\n",
    "\n",
    "* Create a list of skipped studies so they can be returned and printed for the user at the end if requested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying the conditions categorization for each study is challenging. The categories aren't clearly defined; I would need to do topic modeling or keyword analysis on the categories as well to group them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2447850, 'NCT01071824', 'Colon Cancer', 'colon cancer')\n",
      "(2274109, 'NCT02495987', 'ICP', 'icp')\n",
      "(2614334, 'NCT03608072', 'Healthy', 'healthy')\n",
      "(2340732, 'NCT01940796', 'GVHD', 'gvhd')\n",
      "(2300873, 'NCT02266394', 'Renovascular Disease', 'renovascular disease')\n",
      "(2300903, 'NCT02266199', 'Pain', 'pain')\n",
      "(2274296, 'NCT02494492', 'Uveitis', 'uveitis')\n",
      "(2267381, 'NCT02554201', 'Dysuria', 'dysuria')\n",
      "(2274399, 'NCT02493647', 'HIV', 'hiv')\n",
      "(2301080, 'NCT02264665', 'Pancreatic Neuroendocrine Tumor, Well Differentiated and Progressive', 'pancreatic neuroendocrine tumor, well differentiated and progressive')\n",
      "(2336121, 'NCT01977521', 'Mood Disorders', 'mood disorders')\n",
      "(2301533, 'NCT02260466', 'Heart Disease', 'heart disease')\n",
      "(2301534, 'NCT02260466', 'Aging', 'aging')\n",
      "(2166734, 'NCT03364608', 'Asthma', 'asthma')\n",
      "(2268033, 'NCT02548624', 'Pressure Ulcer', 'pressure ulcer')\n",
      "(2301880, 'NCT02257489', 'Musculoskeletal Diseases', 'musculoskeletal diseases')\n",
      "(2275161, 'NCT02486562', 'Multiple Sclerosis', 'multiple sclerosis')\n",
      "(2336737, 'NCT01972113', 'Prediabetes', 'prediabetes')\n",
      "(2268337, 'NCT02545595', 'Morbid Obesity', 'morbid obesity')\n",
      "(2302219, 'NCT02254499', 'Knee Osteoarthritis', 'knee osteoarthritis')\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM conditions LIMIT 20;\"\n",
    "connection_args = json.load(open('login.txt'))\n",
    "connection = pg.connect(**connection_args)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(query)\n",
    "for result in cursor:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error checking and production aspects to add "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One of the error messages is redundant - every study that gives a 'wrong number of inclusion/exclusion' will also give an 'improperly formatted' error\n",
    "* Unit testing: check the output of the functions\n",
    "* add Parameters separated by ------ and Returns followed by ----- to docstrings\n",
    "* add comments to explain difficult to interpret blocks\n",
    "* return skip_list in cleaning function so the user can view all the skipped records at the end of the pipeline - maybe return document, skip_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "d7a55c8c-cd97-469a-a784-0ccb66cd95ac",
    "theme": {
     "d7a55c8c-cd97-469a-a784-0ccb66cd95ac": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "d7a55c8c-cd97-469a-a784-0ccb66cd95ac",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
