{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Asthma Trial inclusion data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Google's pre-trained Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros: Pre-trained  \n",
    "Cons: Likely missing lots of medical terminology important to the meaning of criteria\n",
    "\n",
    "Important check: Capture all words that Word2Vec doesn't recognize in the asthma study subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import community\n",
    "from collections import defaultdict\n",
    "import randomcolor\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Mongo clinical_trials DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_mongo(database, collection):\n",
    "    \n",
    "    \"\"\"\n",
    "    Opens a connection to a specified Mongo DB location\n",
    "    \n",
    "    Input Parameters:\n",
    "    database: name of database to connect to or create (str)\n",
    "    collection: name of collection to connect to or create (str)\n",
    "    \n",
    "    Returns:\n",
    "    The connection object for the database without a collection specified\n",
    "    The connection object for a specific Mongo location (database & collection)\n",
    "    \"\"\"\n",
    "    \n",
    "    client = MongoClient()\n",
    "    db = client[database]\n",
    "    mongo_loc = db[collection]\n",
    "    return db, mongo_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_loc, eligibility_loc = connect_to_mongo('clinical_trials', 'eligibilities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process inclusion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_cursor = eligibility_loc.find({\"inclusion_criteria\": { '$regex' : \".*asthma.*\"}})\n",
    "\n",
    "stoplist = stopwords.words('english')\n",
    "\n",
    "inclusion_texts = []\n",
    "\n",
    "for study in doc_cursor:\n",
    "    for crit in study['cleaned_inclusion']:\n",
    "        words = re.findall('[a-z][a-z]+', crit)\n",
    "        inclusion_tokens = [[word for word in words if word not in stoplist]]\n",
    "        inclusion_texts += inclusion_tokens\n",
    "print(inclusion_texts[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Google's pre-trained Word2Vec model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_vec_file = '/Users/courtney/ds/Word2Vec/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(google_vec_file, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vector for each criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to vectorize each inclusion criteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_words = []\n",
    "\n",
    "def get_doc_vec(words, model):\n",
    "    good_words = []\n",
    "    for word in words:\n",
    "        # Words not in the original model will fail\n",
    "        try:\n",
    "            if model.wv[word] is not None:\n",
    "                good_words.append(word)\n",
    "        except:\n",
    "            if word not in missing_words:\n",
    "                missing_words.append(word)\n",
    "            continue\n",
    "    # If no words are in the original model\n",
    "    if len(good_words) == 0:\n",
    "        return None\n",
    "    # Return the mean of the vectors for all the good words\n",
    "    return model.wv[good_words].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate number of unique keywords in the asthma criteria dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words: 6741 \n",
      "Total words: 122252\n"
     ]
    }
   ],
   "source": [
    "unique_words = []\n",
    "total_word_count = 0\n",
    "for crit in inclusion_texts:\n",
    "    for word in crit:\n",
    "        total_word_count += 1\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "unique_word_count = len(unique_words)\n",
    "print(\"Unique words:\", unique_word_count, \"\\nTotal words:\", total_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize each inclusion criteria "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create empty array to fill with vectrized criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11298, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inclusion_vectors = np.zeros((len(inclusion_texts), 300))\n",
    "inclusion_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize criteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/courtney/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/Users/courtney/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:18: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing 1219 out of 6741 unique words: 18% missing\n",
      "\n",
      "[ 0.10852051  0.23339844 -0.07384491  0.05639648 -0.02832031 -0.04815674\n",
      "  0.22998047 -0.11035156  0.17773438  0.09515381  0.06445312 -0.04302979\n",
      " -0.12330627 -0.17285156 -0.07044983 -0.09249878  0.03405762  0.1496582\n",
      " -0.08163452 -0.12988281 -0.0647583  -0.11698914 -0.13134766 -0.0904541\n",
      " -0.0355835  -0.17211914 -0.05151367  0.11254883  0.04956055  0.02148438\n",
      " -0.04345703 -0.13574219  0.02716064  0.0284729   0.02648926  0.08056641\n",
      " -0.0916748  -0.17919922 -0.11181641  0.17480469  0.06563568  0.0970459\n",
      "  0.09326172 -0.01611328  0.04931641 -0.01098633  0.04443359  0.18701172\n",
      " -0.1164856  -0.0880127  -0.08587646 -0.15991211 -0.21484375 -0.12158203\n",
      "  0.12904739  0.04299927  0.07922363 -0.05505371 -0.18981934 -0.03833008\n",
      " -0.05554199  0.06396484  0.08081055 -0.13882446  0.18188477  0.04833984\n",
      "  0.06176758  0.13983154  0.16992188  0.05651855 -0.04174805 -0.11138916\n",
      " -0.00317383  0.25830078 -0.00390625  0.0871582   0.04637146  0.08178711\n",
      "  0.15307617  0.25463867  0.10424805 -0.16748047 -0.05358887  0.234375\n",
      " -0.15649414  0.06323242 -0.12158203  0.03494263  0.12475586  0.10864258\n",
      "  0.18115234  0.03295898 -0.25878906 -0.11108398 -0.12255859 -0.13696289\n",
      "  0.20251465 -0.00634766  0.03457642 -0.12097168 -0.06689453 -0.02124023\n",
      " -0.21582031  0.08227539 -0.18115234 -0.24755859  0.00683594 -0.05236816\n",
      " -0.0632019   0.03186035  0.12524414  0.04907227 -0.01171875 -0.01116943\n",
      "  0.03710938  0.02575684 -0.03088379 -0.07324219  0.0411377  -0.07849121\n",
      " -0.15405273  0.02545166 -0.03552246  0.01220703  0.12329102  0.01818848\n",
      "  0.29589844  0.00634766  0.03665161  0.13256836 -0.08300781 -0.18310547\n",
      " -0.1776123  -0.11279297 -0.14501953  0.01623535 -0.03152466 -0.00585938\n",
      " -0.10546875  0.05712891  0.02906036 -0.07250977 -0.1055603   0.06506348\n",
      "  0.05740356  0.0670166   0.10644531  0.00097656 -0.12866211 -0.19238281\n",
      "  0.01580811 -0.0456543  -0.08177948  0.00366211 -0.02416992  0.01549911\n",
      "  0.00958252 -0.15869141  0.09472656 -0.17651367  0.08306885  0.10656738\n",
      "  0.14355469 -0.02145386 -0.00610352 -0.02612305 -0.10302734 -0.12670898\n",
      "  0.07922363 -0.03601074  0.01702881 -0.16625977  0.05371094 -0.13500977\n",
      "  0.03277588 -0.03164673  0.01831055  0.02331543 -0.01312256  0.08544922\n",
      " -0.03076172 -0.18847656 -0.04178429  0.04321289  0.05895996  0.04589844\n",
      " -0.00415039 -0.01556396  0.16601562 -0.06176758  0.13574219  0.02246094\n",
      " -0.07086182 -0.0912323  -0.03540039  0.21240234  0.20800781  0.0769043\n",
      " -0.07513428 -0.02471924 -0.15209961 -0.05334473 -0.01690674  0.06506348\n",
      "  0.04907227 -0.11889648 -0.02385974 -0.02667236  0.0135498  -0.01623535\n",
      " -0.00634766 -0.05163574 -0.00457764 -0.03277588 -0.22216797 -0.02146912\n",
      " -0.13269043  0.01000977 -0.03442383  0.07385254 -0.08374023 -0.01831055\n",
      "  0.26416016 -0.13977051  0.11413574 -0.15478516  0.07836914 -0.14038086\n",
      " -0.09975815 -0.06677246  0.04956055 -0.13623047 -0.10668945  0.09805107\n",
      " -0.13305664  0.00292969  0.05505371 -0.10705566  0.00354004  0.12451172\n",
      " -0.02124023 -0.00708008  0.02120972 -0.10961914 -0.20703125  0.04931641\n",
      " -0.05859375  0.02941895  0.00214386  0.01416016  0.13619995 -0.05517578\n",
      "  0.02874756  0.08642578  0.15258789  0.11694336  0.04421997  0.15454102\n",
      " -0.15869141  0.00384521  0.16601562 -0.12805176  0.00341797 -0.04498291\n",
      "  0.15112305  0.11621094 -0.18078613  0.07580566 -0.01931763  0.06317139\n",
      "  0.13305664 -0.06158447  0.15893555  0.00704956  0.05636597  0.01571655\n",
      " -0.03704834 -0.09082031 -0.06738281 -0.12194824 -0.0123291   0.0098381\n",
      " -0.140625    0.06384277 -0.02783203 -0.11816406  0.00854492  0.1328125\n",
      "  0.01489258  0.09936523 -0.00695801  0.06994629 -0.20996094 -0.27148438\n",
      " -0.06539917 -0.1003418  -0.06530762  0.02270508  0.02770996 -0.04321289] \n",
      "\n",
      "['age', 'year']\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(inclusion_texts):\n",
    "    vec = get_doc_vec(doc, model)\n",
    "    inclusion_vectors[i, :] = vec\n",
    "print(f\"\\nMissing {len(missing_words)} out of {unique_word_count} unique words: {round(len(missing_words)/unique_word_count*100)}% missing\\n\")\n",
    "print(vec, '\\n')\n",
    "print(inclusion_texts[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18% of unique words are missing in Word2Vec. Most of them are numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(missing_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219\n"
     ]
    }
   ],
   "source": [
    "print(len(missing_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring how well GoogleNews Word2Vec performs on medical words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('gene' ,topn=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('pollen' ,topn=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('mg_dL' ,topn=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle vectorized eligibility criteria  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(inclusion_vectors, open(\"vectorized_criteria.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
